import sherpa_onnx
import sounddevice as sd
import numpy as np
import queue
import sys
import re

def main():
    # ==========================================
    # 1. é…ç½® SenseVoice æ¨¡å‹
    # ==========================================
    model_dir = "./models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17"
    
    # ä¸ºäº†ç•Œé¢æ›´å¹²å‡€ï¼Œæˆ‘ä»¬æŠŠåŠ è½½æ—¥å¿—ä¹Ÿç®€åŒ–ä¸€ä¸‹
    print("-" * 50)
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹ SenseVoice ...", end="", flush=True)

    try:
        recognizer = sherpa_onnx.OfflineRecognizer.from_sense_voice(
            model=f"{model_dir}/model.int8.onnx",
            tokens=f"{model_dir}/tokens.txt",
            num_threads=1,
            use_itn=True,
            decoding_method="greedy_search",
        )
        print(" [å®Œæˆ]")
    except Exception as e:
        print(f"\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # ==========================================
    # 2. éº¦å…‹é£å‚æ•°
    # ==========================================
    SAMPLE_RATE = 16000
    SILENCE_THRESHOLD = 0.03  # çµæ•åº¦ (ç¯å¢ƒåµå°±è°ƒå¤§ï¼Œæ¯”å¦‚ 0.05)
    PAUSE_LIMIT = 35          # åœé¡¿åˆ¤å®š (çº¦ 0.8-1.0ç§’)
    
    audio_queue = queue.Queue()

    def callback(indata, frames, time, status):
        if status:
            pass # å¿½ç•¥åº•å±‚è­¦å‘Šï¼Œä¿æŒç•Œé¢å¹²å‡€
        audio_queue.put(indata.copy())

    print("-" * 50)
    print("  ğŸ“  å¬å†™å·²å¼€å§‹ (è¯·è¯´è¯ï¼Œè¯´å®Œåœé¡¿å³å¯ä¸Šå±)")
    print("-" * 50)

    with sd.InputStream(channels=1, dtype="float32", samplerate=SAMPLE_RATE, callback=callback):
        buffer = []
        silent_frames = 0
        is_speaking = False
        
        while True:
            frame = audio_queue.get()
            volume = np.linalg.norm(frame) * 10
            
            # === çŠ¶æ€æœºé€»è¾‘ ===
            if volume > SILENCE_THRESHOLD:
                # æ­£åœ¨è¯´è¯
                is_speaking = True
                silent_frames = 0
                buffer.append(frame)
                # [ä¿®æ”¹å¤„]ï¼šå»æ‰äº†è¿™é‡Œçš„ print(".", ...)
                
            else:
                # å½“å‰é™éŸ³
                if is_speaking:
                    buffer.append(frame)
                    silent_frames += 1
                    
                    # åˆ¤å®šä¸€å¥ç»“æŸ
                    if silent_frames > PAUSE_LIMIT: 
                        # æ‰“å°ä¸€ä¸ªä¸´æ—¶çš„çŠ¶æ€ï¼Œå‘Šè¯‰ç”¨æˆ·æ­£åœ¨ç®—
                        # \r å¯ä»¥è®©å…‰æ ‡å›åˆ°è¡Œé¦–ï¼Œé¿å…æ¢è¡Œ
                        print("\r[æ­£åœ¨è¯†åˆ«...]", end="", flush=True)
                        
                        # 1. è¯†åˆ«
                        full_audio = np.concatenate(buffer)
                        stream = recognizer.create_stream()
                        stream.accept_waveform(SAMPLE_RATE, full_audio)
                        recognizer.decode_stream(stream)
                        
                        # 2. è·å–æ–‡æœ¬
                        text = stream.result.text
                        text = re.sub(r'<\|.*?\|>', '', text).strip()
                        
                        # æ¸…é™¤ "[æ­£åœ¨è¯†åˆ«...]" è¿™è¡Œå­— (ç”¨ç©ºæ ¼è¦†ç›–)
                        print("\r" + " " * 20 + "\r", end="", flush=True)
                        
                        if len(text) > 0:
                            # 3. æ‰“å°ç»“æœ
                            print(f"> {text}")
                        
                        # é‡ç½®
                        buffer = []
                        is_speaking = False
                        silent_frames = 0
                else:
                    pass

if __name__ == "__main__":
    main()
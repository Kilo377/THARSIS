# **THARSIS: Context-Aware Human-Centric Intelligence**

A unified platform for **deep multimodal human perception**, **privacy-enhanced digital twin generation**, and **intent nowcasting**.

<video src="demo.mp4" controls width="600"></video>

---

## **Overview**

THARSIS builds an AI-native, human-centric perception system.  
It bridges **physical sensing** and **digital cognition**, generating a privacy-preserving digital twin capable of **continuous state understanding**, **intent prediction**, and **context-aware behavior modeling**.

<img width="2086" height="792" alt="image" src="https://github.com/user-attachments/assets/db1059f1-57a8-45d9-ae09-6599240bdb5c" />

---

## **ðŸ”¥ Motivations**

### **1. Narrow Perceptual Dimensions**
Most systems rely on surface-level behavior features, lacking:
- affective understanding  
- behavioral continuity  
- environmental causal context  

### **2. Fragmented & Sensitive Data**
Multimodal sensory streams are:
- fragmented across devices  
- difficult to align  
- privacy-sensitive and unsafe for direct cloud processing  

### **3. Weak Intent Modeling**
Conventional systems are reactive.  
They struggle with:
- implicit intent detection  
- causal reasoning across user behavior  
- lack of high-quality intent-labeled datasets  

---

## **ðŸš€ System Architecture**

### **1. Perception Layer â€” Multimodal Sensing**
High-dimensional continuous perception from:
- RGB video  
- audio  
- motion & position  
- biosignals (EEG, heart rate, etc.)  

Real-time extraction of user state:  
**emotion, action, location, posture, attention, activity continuity**.

---

### **2. Synthesis Layer â€” Privacy-Enhanced State Abstraction**
Local processing performs:
- multimodal feature extraction  
- temporal alignment  
- semantic compression  
- privacy-preserving transformation  

Output:  
**natural-language state snapshots** of user + environment.

---

### **3. Digital Twin Layer â€” Intent-Labeled Dataset Generation**
The system constructs a **detached, privacy-independent digital twin**, enabling:

- retrospective intent labeling  
- Action â†’ Intent causal chain construction  
- dataset generation for training **Nowcast/Forecast models**  

<img width="494" height="444" src="https://github.com/user-attachments/assets/53783faf-8ab4-47e1-9958-75345cb27e41" />

---

## **Key Capabilities**

- Continuous multimodal human modeling  
- Causal reasoning over actions and contexts  
- Personalized digital twin representations  
- Real-time intent understanding and prediction  
- Privacy-by-design local processing  
- Lightweight dataset generation pipeline  

---

## **Contributors**

**Chongyu Bao**  
University of Bristol, Smart Internet Lab  

**HaoKai Yang**  
University of Bristol, Smart Internet Lab  

